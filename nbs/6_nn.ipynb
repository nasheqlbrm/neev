{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "689a8e4c",
   "metadata": {},
   "source": [
    "# nn\n",
    "\n",
    "> A description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5073b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d66819",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f894104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import random\n",
    "from neev.engine import Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bf6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Module:\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters():\n",
    "            p.grad = 0\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class Neuron(Module):\n",
    "    def __init__(self, \n",
    "                 nin, # number of inputs to the neuron\n",
    "                 nonlin=True # do we have a non-linearity at the end\n",
    "                ):\n",
    "        self.w = [Value(random.uniform(-1,1)) for i in range(nin)]\n",
    "        self.b = Value(random.uniform(-1,1))\n",
    "        self.nonlin = nonlin\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        act =  sum((wi*xi for wi,xi in zip(self.w, x)), self.b)\n",
    "        return act.relu() if self.nonlin else act\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{'ReLU' if self.nonlin else 'Linear'}Neuron({len(self.w)})\"   \n",
    "    \n",
    "class Layer(Module):\n",
    "    def __init__(self, \n",
    "                 nin,#number of inputs to each neuron in the layer \n",
    "                 nout,#number of neurons in the layer\n",
    "                 **kwargs\n",
    "                ):\n",
    "        self.neurons = [Neuron(nin, **kwargs) for _ in range(nout)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outs = [n(x) for n in self.neurons]\n",
    "        return outs[0] if len(outs) == 1 else outs\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for n in self.neurons for p in n.parameters()]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Layer of [{', '.join(str(n) for n in self.neurons)}]\"    \n",
    "\n",
    "    \n",
    "class MLP(Module):\n",
    "    def __init__(self, \n",
    "                 nin,#number of inputs to each neuron in the layer  \n",
    "                 nouts # list with the number of neurons in each layer of the MLP\n",
    "                ):\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for l in self.layers for p in l.parameters()]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"MLP of [{', '.join(str(layer) for layer in self.layers)}]\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a60cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=0.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "x = [2.0,3.0]\n",
    "n = Neuron(2)\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a88b54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=0.14131627735144314),\n",
       " Value(data=2.015731845254659),\n",
       " Value(data=2.815106788968965)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "# we want 3 neurons in our layer, each neuron will take two inputs\n",
    "l = Layer(2,3)\n",
    "l(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182126c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=0.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### |hide\n",
    "# we want 3 layers in our MLP\n",
    "# with 4 neurons in the first, 4 in the second\n",
    "# 1 neuron in the output layer\n",
    "# each neuron in the MLP will take three inputs\n",
    "n = MLP(3,[4,4,1])\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f8d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "assert len(n.parameters()) == 4*4 + 4*5 + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee60ffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from neev.viz import view_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d367e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# view_dot(n(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfc9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "xs = [\n",
    "    [2.0,3.0,-1.0],\n",
    "    [3.0,-1.0,0.5],\n",
    "    [0.5,1.0,1.0],\n",
    "    [1.0,1.0,-1.0]\n",
    "]\n",
    "ys= [1.0,-1.0,-1.0,1.0] #targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dafae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,4.0\n",
      "1,4.0\n",
      "2,4.0\n",
      "3,4.0\n",
      "4,4.0\n",
      "5,4.0\n",
      "6,4.0\n",
      "7,4.0\n",
      "8,4.0\n",
      "9,4.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Value(data=0.0), Value(data=0.0), Value(data=0.0), Value(data=0.0)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "for k in range(10):\n",
    "    # forward pass\n",
    "    ypred =[n(x) for x in xs]\n",
    "#     print(ypred)\n",
    "    loss = sum((yout-ygt)**2 for ygt,yout in zip(ys,ypred))\n",
    "    \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "#     print(n.layers[0].neurons[0].w[0].grad)\n",
    "#     print(n.layers[0].neurons[0].w[0].data)\n",
    "\n",
    "    # update\n",
    "    for p in n.parameters():\n",
    "        p.data += -0.05 *p.grad\n",
    "        \n",
    "    print(f'{k},{loss.data}')\n",
    "\n",
    "ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aec7ad9",
   "metadata": {},
   "source": [
    "#|hide\n",
    "\n",
    "The training loop above has a bug. Can you spot it?\n",
    "\n",
    "Essentially we forgot to zero out the gradients!! The gradients continued to accumulate and essentially gave us a huge step size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "n = MLP(3,[4,4,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89510f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,3.7741061956415867\n",
      "1,3.36266237838855\n",
      "2,3.1721306456753666\n",
      "3,2.9039711843015144\n",
      "4,2.58831208728076\n",
      "5,2.259529690772081\n",
      "6,2.2625080262353623\n",
      "7,2.395826249522481\n",
      "8,2.7311816317761255\n",
      "9,2.126828783173646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Value(data=1.3541630250597492),\n",
       " Value(data=0.0),\n",
       " Value(data=0.0),\n",
       " Value(data=1.0373809423927969)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "for k in range(10):\n",
    "    # forward pass\n",
    "    ypred =[n(x) for x in xs]\n",
    "    loss = sum((yout-ygt)**2 for ygt,yout in zip(ys,ypred))\n",
    "    \n",
    "    # backward pass\n",
    "    for p in n.parameters():\n",
    "        p.grad = 0 #zero grad\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    for p in n.parameters():\n",
    "        p.data += -0.05 * p.grad\n",
    "        p.grad = 0\n",
    "        \n",
    "    print(f'{k},{loss.data}')\n",
    "\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5450746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# view_dot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e51cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
