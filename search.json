[
  {
    "objectID": "nn.html",
    "href": "nn.html",
    "title": "nn",
    "section": "",
    "text": "source\n\nMLP\n\n MLP (nin, nouts)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\nDetails\n\n\n\n\nnin\nnumber of inputs to each neuron in the layer\n\n\nnouts\nlist with the number of neurons in each layer of the MLP\n\n\n\n\nsource\n\n\nLayer\n\n Layer (nin, nout, **kwargs)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\nDetails\n\n\n\n\nnin\nnumber of inputs to each neuron in the layer\n\n\nnout\nnumber of neurons in the layer\n\n\nkwargs\n\n\n\n\n\nsource\n\n\nNeuron\n\n Neuron (nin, nonlin=True)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnin\n\n\nnumber of inputs to the neuron\n\n\nnonlin\nbool\nTrue\ndo we have a non-linearity at the end\n\n\n\n\nsource\n\n\nModule\n\n Module ()\n\nInitialize self. See help(type(self)) for accurate signature.\n\n### |hide\n# we want 3 layers in our MLP\n# with 4 neurons in the first, 4 in the second\n# 1 neuron in the output layer\n# each neuron in the MLP will take three inputs\nn = MLP(3,[4,4,1])\nn(x)\n\nValue(data=0.3513214887908616, grad=0)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "neev",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "neev",
    "section": "Install",
    "text": "Install\npip install neev"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "neev",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2"
  },
  {
    "objectID": "manual_backprop_example_1.html",
    "href": "manual_backprop_example_1.html",
    "title": "Manual backprop examples",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "manual_backprop_example_1.html#numerical-evaluation-of-the-derivative",
    "href": "manual_backprop_example_1.html#numerical-evaluation-of-the-derivative",
    "title": "Manual backprop examples",
    "section": "Numerical evaluation of the derivative",
    "text": "Numerical evaluation of the derivative\nIf we nudge the input from \\(3\\) to slightly above say \\(3+h\\) (for some \\(h>0\\)) how do we expect the function above to respond? Well we expect it to go up. The \\(\\hbox{slope}=\\frac{f(x+h)-f(x)}{h}\\) measures the rate at which the function responds per unit increment of the input.\n\ndef f(x):\n    return 3*x**2 - 4*x + 5\n\n\nh = 0.00000001\nx = 3.\n( f(x+h) - f(x) )/h\n\n14.00000009255109\n\n\n\nHow small of an h?\nThe mathematical definition of derivative requires us to take h to zero. However since we are working with floating point arithmetic and the represenation of these numbers are finite so making h too small will get us into trouble.\n\n{h : ( f(x+h) - f(x) )/h for h in [0.001, 0.0001, 0.00000001, 0.0000000000000001]}\n\n{0.001: 14.00300000000243,\n 0.0001: 14.000300000063248,\n 1e-08: 14.00000009255109,\n 1e-16: 0.0}\n\n\n\n# If the slope is negative the function will go down when we nudge the input upward.\nx = -3.\n(f(x+h) - f(x))/h\n\n-22.00000039920269\n\n\nIs there a point where the function does not respond at all if we were to nudge it? Why yes, in this case we see that happens at 2/3\n\nx = 2/3.\n(f(x+h) - f(x))/h\n\n0.0\n\n\nLet’s get more complex We define d to be a function of three scalar inputs a, b and c\n\na, b, c = 2., -3., 10.\nd = a*b + c\nprint(d)\n\n4.0\n\n\nLet’s look at the derivative of d with respect to a, b and c\n\nh = 0.0001\na, b, c = 2., -3., 10.\n\nd1 = a*b + c\n\nprint('d1',d1)\n\nd1 4.0\n\n\nIf we nudge a up will the function go up or down?\n\na += h\nd2 = a*b + c\n\nIt will go down. a is slightly higher but it is being multiplied by a negative number so the product itself is slightly larger negative number than before. Hence the function will go down.\n\nprint('d1',d1)\nprint('d2',d2)\n\nd1 4.0\nd2 3.999699999999999\n\n\nThe above tells us the slope will be a negative number\n\nprint('slope', (d2-d1)/h)\n\nslope -3.000000000010772\n\n\nIf we nudge b up will the function go up or down?\n\nh = 0.0001\na, b, c = 2., -3., 10.\n\nd1 = a*b + c\nb += h\nd2 = a*b + c\nprint('d1',d1)\nprint('d2',d2)\nprint('slope',(d2-d1)/h)\n\nd1 4.0\nd2 4.0002\nslope 2.0000000000042206\n\n\nFinally, examine the influence of c on the output. If we nudge c up will the function go up or down?\n\nh = 0.0001\na, b, c = 2., -3., 10.\n\nd1 = a*b + c\nc += h\nd2 = a*b + c\nprint('d1',d1)\nprint('d2',d2)\nprint('slope',(d2-d1)/h)\n\nd1 4.0\nd2 4.0001\nslope 0.9999999999976694\n\n\n\nfrom neev.engine import *\n\n\na = Value(2., label='a')\na\n\nValue(data=2.0)\n\n\n\nb = Value(-3, label='b')\na+b\n\nValue(data=-1.0)\n\n\n\nc = Value(10., label='c')\ne = a*b; e.label = 'e'\nd = e + c; d.label = 'd'\nd\n\nValue(data=4.0)\n\n\n\nd._prev\n\n{Value(data=-6.0), Value(data=10.0)}\n\n\n\nd._op\n\n'+'\n\n\n\nf = Value(-2.); f.label='f'\nL = d*f; L.label = 'L'\nL\n\nValue(data=-8.0)\n\n\n\nfrom neev.viz import *\n\n\n\n\nVisualize the computation graph. Observe that all the grad values are zero. We will start filling them in manually.\n\nview_dot(L)\n\n\n\n\ndL_d can be used to check each of the gradients that we will be manually computing.\n\ndef dL_d(what='L'):\n    '''nudge the parameter specified in the `what` by a small amount,\n        compute the gradient numerically and return it.\n    '''\n    \n    if what not in ['a','b','c','d','e','f','L']:\n        raise Exception\n        \n    h_a = 0.0001 if what=='a' else 0\n    h_b = 0.0001 if what=='b' else 0\n    h_c = 0.0001 if what=='c' else 0   \n    h_d = 0.0001 if what=='d' else 0\n    h_e = 0.0001 if what=='e' else 0\n    h_f = 0.0001 if what=='f' else 0    \n    h_L = 0.0001 if what=='L' else 0\n    \n    a,b,c = Value(2.,label='a'),Value(-3.,label='b'),Value(10.,label='c')\n    e = a*b; e.label = 'e'\n    d = e + c; d.label = 'd'\n    f = Value(-2.); f.label='f'\n    L = d*f; L.label = 'L'\n    L1 = L.data\n\n    a,b,c = Value(2.+h_a,label='a'),Value(-3.+h_b,label='b'),Value(10.+h_c,label='c')\n    e = a*b;e.data += h_e; e.label = 'e'\n    d = e + c; d.data += h_d; d.label = 'd'\n    f = Value(-2.);f.data += h_f; f.label='f'\n    L = d*f; L.label = 'L'\n    L2 = L.data + h_L\n    \n    return ((L2-L1)/h)\n\nNow that we have filled in the gradients for \\(L,d\\) and \\(f\\) let’s visualize the computation graph.\n\nview_dot(L)\n\n\n\n\n\n# The gradients from our manual and the numerical check are the same up to \"floating point funkiness\"\ndL_d('L'), L.grad\n\n(0.9999999999976694, 1)"
  },
  {
    "objectID": "manual_backprop_example_1.html#gradients-for-the-middle-layer",
    "href": "manual_backprop_example_1.html#gradients-for-the-middle-layer",
    "title": "Manual backprop examples",
    "section": "Gradients for the middle layer",
    "text": "Gradients for the middle layer\nNext we derive gradients for the middle layer starting with \\(\\frac{\\partial L}{\\partial c}\\). We need to understand how \\(L\\) responds when \\(c\\) is wiggled. This effect is transmitted through \\(d\\) and recall that we derived earlier how \\(L\\) responds when \\(d\\) is wiggled. So if we can figure out how \\(c\\) impacts \\(d\\) then we can put that together with the information on how \\(d\\) impacts \\(L\\) to determine how \\(c\\) impacts \\(L\\).\nPer Karpathy, “This is crucial, if you understand the gradient of node \\(c\\) then you understand all of backpropagation and all of the training of neural nets.”\n\\(\\frac{\\partial L}{\\partial c} = \\frac{\\partial d}{\\partial c}*\\frac{\\partial L}{\\partial d}\\)\nSince \\(d = e + c\\) we have that \\(\\frac{\\partial d}{\\partial c} = 1\\) (the “local” derivative of the sum expression is simple).\nOr \\(\\frac{\\partial L}{\\partial c} = 1*\\frac{\\partial L}{\\partial d} = \\frac{\\partial L}{\\partial d}\\)\nSimilarly, \\(\\frac{\\partial L}{\\partial e} = \\frac{\\partial L}{\\partial d}\\).\nSo the sum node distributes the incoming gradient as-is to each of it’s children.\n\nc.grad = d.grad\ne.grad = d.grad\n\n\nview_dot(L)\n\n\n\n\n\ndL_d('c'), d.grad\n\n(-1.9999999999953388, -2.0)\n\n\n\ndL_d('e'), d.grad\n\n(-1.9999999999953388, -2.0)\n\n\nWhat is \\(\\frac{\\partial L}{\\partial a}\\)?\nIt is \\(\\frac{\\partial e}{\\partial a}*\\frac{\\partial L}{\\partial e} = b*\\frac{\\partial L}{\\partial e} = -3*-2 = 6\\)\n\na.grad=e.grad * b.data\na.grad\n\n6.0\n\n\n\ndL_d('a')\n\n6.000000000021544\n\n\nSimilarly \\(\\frac{\\partial L}{\\partial b} = \\frac{\\partial e}{\\partial b}*\\frac{\\partial L}{\\partial e} = a*\\frac{\\partial L}{\\partial e} = 2*-2=-4\\)\n\n# Manually compute gradients\nb.grad=e.grad * a.data\nb.grad\n\n-4.0\n\n\n\nd.grad\n\n-2.0\n\n\nAt this point we have manually backpropagated through this simple example and verified that they are correct using the dl_d.\n\nview_dot(L)"
  },
  {
    "objectID": "manual_backprop_example_1.html#make-l-increase",
    "href": "manual_backprop_example_1.html#make-l-increase",
    "title": "Manual backprop examples",
    "section": "Make L increase",
    "text": "Make L increase\nNext let’s nudge of the leaf nodes that we control so as to make \\(L\\) increase.\nHow? Well we observe that:\n\nIf the value of a leaf node that we control is positive and the gradient is positive then nudging the value of such a leaf node up will make the loss go up.\n\nNudging such a value by an amount which is \\(0.01\\) times the gradient, will make us go from a positive value to a more positive value (thus nudging the value up) and this will make the loss go up.\nThis is the case for \\(a\\) it’s value is \\(2\\) and it’s gradient is \\(6\\)\n\nIf the value of a leaf node that we control is positive and the gradient is negative then that means that nudging the value of such a leaf node up will make the loss go down.\n\nNudging such a value by an amount which is \\(0.01\\) times the gradient, will make us go from a positive value to a less positive value (thus nudging the value down) and this will make the loss go up.\nThis is the case for \\(c\\) it’s value is \\(10\\) and it’s gradient is \\(-2\\)\n\nIf the value of a leaf node that we control is negative and the gradient is positive then that nudging the value of such a leaf node up will make the loss go up.\n\nNudging such a value by an amount which is \\(0.01\\) times the gradient, will make us go from a negative value to a less negative value (thus nudging the value up) and this will make the loss go up.\nThis is the case for \\(f\\) it’s value is \\(-2\\) and it’s gradient is \\(4\\)\n\nIf the value of a leaf node that we control is negative and the gradient is negative then that nudging the value of such a leaf node up will make the loss go down.\n\nNudging such a value by an amount which is \\(0.01\\) times the gradient, will make us go from a negative value to a more negative value (thus nudging the value down) and this will make the loss go up.\nThis is the case for \\(b\\) it’s value is \\(-3\\) and it’s gradient is \\(-4\\)\n\n\nTL;DR\n\nThe strategy to increase the loss, in all cases, is to nudge the value by some small number times the gradient.\nConversely to decrease the lose we need to nudge the value by some small number times the negative of the gradient.\n\n\n# forward pass\na,b,c = Value(2.,label='a'),Value(-3.,label='b'),Value(10.,label='c')\ne = a*b; e.label = 'e'\nd = e + c; d.label = 'd'\nf = Value(-2); f.label='f'\nL = d*f; L.label = 'L'\nL\n\nValue(data=-8.0)\n\n\nHooray, \\(L\\) increased from \\(-8\\) to \\(-7.28\\)!"
  },
  {
    "objectID": "manual_backprop_example_1.html#example-2",
    "href": "manual_backprop_example_1.html#example-2",
    "title": "Manual backprop examples",
    "section": "Example 2",
    "text": "Example 2\n\nbias \\(b\\) is the “innate trigger happiness” of the neuron\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n\n# weights of the neuron\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n\n# bias of the neuron\nb = Value(6.881375870195432, label='b')\n\nx1w1 = x1*w1; x1w1.label='x1w1'\nx2w2 = x2*w2; x2w2.label='x2w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label='x1w1+x2w2'\nn = x1w1x2w2 + b; n.label='n'\n\no= n.tanh(); o.label='o'\n\n\nview_dot(o)\n\n\n\n\n\\(\\frac{\\partial o}{\\partial o} = 1\\)\n\no.grad = 1 #do_do = 1\n\n\\(\\frac{\\partial o}{\\partial n} = \\frac{\\partial \\tanh(n)}{\\partial n} = 1-\\tanh(n)^2 = 1 - o^2\\)\n\nn.grad =  1 - (o.data**2)\n\nRecall that the plus (+) operator acts as a distributor of gradients so it will just flow the back the incoming gradient to it’s children nodes. It’s helpful to think of the gradient as flowing from the left to the right.\n\nb.grad = n.grad\nx1w1x2w2.grad = n.grad\nview_dot(o)\n\n\n\n\nNext we encounter the + operator again so we distribute the incoming \\(0.5\\) to both \\(x1w1\\) and \\(x2w2\\).\n\nx1w1.grad = x1w1x2w2.grad\nx2w2.grad = x1w1x2w2.grad\nview_dot(o)\n\n\n\n\nFor the * operator for \\(x1w1\\) we know that \\(x1\\)’s local grad will be \\(w1\\)’s data. So,\n\nx1.grad = w1.data*x1w1.grad\n\n\n# Similarly,\nw1.grad = x1.data*x1w1.grad\n\n\nx2.grad = w2.data*x2w2.grad\nw2.grad = x2.data*x2w2.grad\n\n\nview_dot(o)"
  },
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "More examples",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\n\n\nfrom neev.engine import *\nfrom neev.viz import *\n\n\n## Example 2: Neuron\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n\n# weights of the neuron\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n\nx1w1 = x1*w1; x1w1.label='x1w1'\nx2w2 = x2*w2; x2w2.label='x2w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label='x1w1+x2w2'\nn = x1w1x2w2 + b; n.label='n'\n\no= n.tanh(); o.label='o'\no.backward()\nview_dot(o)\n\n\n\n\n\n## Example 2: Neuron\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n\n# weights of the neuron\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n\n# bias of the neuron\nb = Value(6.8813735870195432, label='b')\n\nx1w1 = x1*w1; x1w1.label='x1w1'\nx2w2 = x2*w2; x2w2.label='x2w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label='x1w1+x2w2'\nn = x1w1x2w2 + b; n.label='n'\n\ne= (2*n).exp() ;e.label='e'\no = (e-1.)/(e+1.); o.label='o'\n\no.backward()\nview_dot(o)"
  },
  {
    "objectID": "viz.html",
    "href": "viz.html",
    "title": "viz",
    "section": "",
    "text": "Install fastdot using mamba install -c fastai fastdot\n\nsource\n\ntrace\n\n trace (root:neev.engine.Value)\n\nbuilds a set of all nodes and edges in a graph\n\n\n\n\nType\nDetails\n\n\n\n\nroot\nValue\nroot node of the computation graph\n\n\n\n\nsource\n\n\nget_dot\n\n get_dot (root:neev.engine.Value, rankdir='LR')\n\nget a pydot graph corresponding to this computation graph\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nroot\nValue\n\nroot node of the computation graph\n\n\nrankdir\nstr\nLR\nTB (top to bottom graph) | LR (left to right)\n\n\n\n\nsource\n\n\nview_dot\n\n view_dot (root:neev.engine.Value)\n\nview the computation graph as a svg\n\n\n\n\nType\nDetails\n\n\n\n\nroot\nValue\nroot node of the computation graphg:pydot.Dot\n\n\n\n\n# inputs x1,x2\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n\n# weights of the neuron\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n\n# bias of the neuron\nb = Value(6.7, label='b')\n\nx1w1 = x1*w1; x1w1.label='x1w1'\nx2w2 = x2*w2; x2w2.label='x2w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label='x1w1+x2w2'\nn = x1w1x2w2 + b; n.label='n'\n\no= n.tanh(); o.label='o'\nview_dot(o)"
  },
  {
    "objectID": "engine.html",
    "href": "engine.html",
    "title": "engine",
    "section": "",
    "text": "source\n\nValue\n\n Value (data, _children=(), _op='', label='')\n\nstores a single scalar value and its gradient\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\n\n\na scalar value\n\n\n_children\ntuple\n()\nThe children of this value\n\n\n_op\nstr\n\nThe operation (such as +,-,*,tanh etc) that created this value\n\n\nlabel\nstr\n\n\n\n\n\n\na = Value(3., label='a')\nb = a+a; b.label='b'\n\nb.backward()\n\nassert a.grad == 2\n\n\na = Value(-2., label='a')\nb = Value(3., label='b')\nd = a*b; d.label='d'\ne = a+b; e.label='e'\nf = d*e; f.label='f'\n\nf.backward()\n\na.grad, b.grad\n\n(-3.0, -8.0)\n\n\n\na = Value(2.)\na+1\n\nValue(data=3.0, grad=0)"
  },
  {
    "objectID": "demo.html",
    "href": "demo.html",
    "title": "Demo",
    "section": "",
    "text": "import random\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nfrom neev.engine import Value\nfrom neev.nn import Neuron, Layer, MLP\n\n\nnp.random.seed(1337)\nrandom.seed(1337)\n\n\n# make up a dataset\n\nfrom sklearn.datasets import make_moons, make_blobs\nX, y = make_moons(n_samples=100, noise=0.1)\n\ny = y*2 - 1 # make y be -1 or 1\n# visualize in 2D\nplt.figure(figsize=(4,4))\nplt.scatter(X[:,0], X[:,1], c=y, s=20, cmap='jet')\n\n<matplotlib.collections.PathCollection>\n\n\n\n\n\n\nX[0:2]\n\narray([[ 1.12211461,  0.08147717],\n       [-0.81882941,  0.05879006]])\n\n\n\ny[:2]\n\narray([-1, -1])\n\n\n\n# initialize a model \nmodel = MLP(2, [16, 16, 1]) # 2-layer neural network\nprint(model)\nprint(\"number of parameters\", len(model.parameters()))\n\nMLP of [Layer of [ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2), ReLUNeuron(2)], Layer of [ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16), ReLUNeuron(16)], Layer of [LinearNeuron(16)]]\nnumber of parameters 337\n\n\n\n# loss function\ndef loss(batch_size=None):\n    # inline DataLoader :)\n    if batch_size is None:\n        Xb, yb = X, y\n    else:\n        ri = np.random.permutation(X.shape[0])[:batch_size]\n        Xb, yb = X[ri], y[ri]\n    inputs = [list(map(Value, xrow)) for xrow in Xb]\n    \n    # forward the model to get scores\n    scores = list(map(model, inputs))\n    \n    # svm \"max-margin\" loss\n    losses = [(1 + -yi*scorei).relu() for yi, scorei in zip(yb, scores)]\n    data_loss = sum(losses) * (1.0 / len(losses))\n    # L2 regularization\n    alpha = 1e-4\n    reg_loss = alpha * sum((p*p for p in model.parameters()))\n    total_loss = data_loss + reg_loss\n    \n    # also get accuracy\n    accuracy = [(yi > 0) == (scorei.data > 0) for yi, scorei in zip(yb, scores)]\n    return total_loss, sum(accuracy) / len(accuracy)\n\n\ntotal_loss, acc = loss()\nprint(total_loss, acc)\n\nValue(data=1.1815924818239036, grad=0) 0.5\n\n\n\n# optimization\nk,total_loss, acc = None, None, None\nfor k in range(100):\n    \n    # forward\n    total_loss, acc = loss()\n    \n    # backward\n    model.zero_grad()\n    total_loss.backward()\n    \n    # update (sgd)\n    learning_rate = 1.0 - 0.9*k/100\n    for p in model.parameters():\n        p.data -= learning_rate * p.grad\n    \n    if k % 10 == 0:\n        print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")\n        \nprint(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")\n\nstep 0 loss 1.1815924818239036, accuracy 50.0%\nstep 10 loss 0.3176038682804337, accuracy 89.0%\nstep 20 loss 0.2257774437880123, accuracy 92.0%\nstep 30 loss 0.35027887399625013, accuracy 89.0%\nstep 40 loss 0.09745912726682808, accuracy 95.0%\nstep 50 loss 0.052438012426209935, accuracy 99.0%\nstep 60 loss 0.036989018681936485, accuracy 100.0%\nstep 70 loss 0.018699428103430678, accuracy 100.0%\nstep 80 loss 0.016688519606967205, accuracy 100.0%\nstep 90 loss 0.014652049002652023, accuracy 100.0%\nstep 99 loss 0.01352435799993184, accuracy 100.0%\n\n\n\n# visualize decision boundary\n\nh = 0.25\nx_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\ny_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\n\nXmesh = np.c_[xx.ravel(), yy.ravel()]\n\n\n# apply Value on each element in xrow\ninputs = [list(map(Value, xrow)) for xrow in Xmesh]\nscores = list(map(model, inputs))\n\n\ninputs[0]\n\n[Value(data=-2.0221939055140945, grad=0),\n Value(data=-1.548639298268643, grad=0)]\n\n\n\nscores[0]\n\nValue(data=-4.784904563750658, grad=0)\n\n\n\nZ = np.array([s.data > 0 for s in scores])\nZ = Z.reshape(xx.shape)\n\n\nfig = plt.figure()\nplt.contourf(xx, yy, Z, cmap=plt.cm.Spectral, alpha=0.8)\nplt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\n\n(-1.548639298268643, 1.951360701731357)"
  }
]