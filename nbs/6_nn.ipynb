{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bc332ff",
   "metadata": {},
   "source": [
    "# nn\n",
    "\n",
    "> A description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e82e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de01429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47da21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import random\n",
    "from neev.engine import Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d81ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Neuron:\n",
    "    def __init__(self, \n",
    "                 nin # number of inputs to the neuron\n",
    "                ):\n",
    "        self.w = [Value(random.uniform(-1,1)) for i in range(nin)]\n",
    "        self.b = Value(random.uniform(-1,1))\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        act =  sum((wi*xi for wi,xi in zip(self.w, x)), self.b)\n",
    "        o = act.tanh()\n",
    "        return o\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "    \n",
    "class Layer:\n",
    "    def __init__(self, \n",
    "                 nin,#number of inputs to each neuron in the layer \n",
    "                 nout#number of neurons in the layer\n",
    "                ):\n",
    "        self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outs = [n(x) for n in self.neurons]\n",
    "        return outs[0] if len(outs) == 1 else outs\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for n in self.neurons for p in n.parameters()]\n",
    "\n",
    "    \n",
    "class MLP:\n",
    "    def __init__(self, \n",
    "                 nin,#number of inputs to each neuron in the layer  \n",
    "                 nouts # list with the number of neurons in each layer of the MLP\n",
    "                ):\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for l in self.layers for p in l.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e6fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=0.9104111583489728)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "x = [2.0,3.0]\n",
    "n = Neuron(2)\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7c9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data=-0.9891878901787617),\n",
       " Value(data=-0.9969669092439016),\n",
       " Value(data=0.9998805782448378)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "# we want 3 neurons in our layer, each neuron will take two inputs\n",
    "l = Layer(2,3)\n",
    "l(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c810cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=-0.9508978458604742)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### |hide\n",
    "# we want 3 layers in our MLP\n",
    "# with 4 neurons in the first, 4 in the second\n",
    "# 1 neuron in the output layer\n",
    "# each neuron in the MLP will take three inputs\n",
    "n = MLP(3,[4,4,1])\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c54723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "assert len(n.parameters()) == 4*4 + 4*5 + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace345ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from neev.viz import view_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd17720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# view_dot(n(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "xs = [\n",
    "    [2.0,3.0,-1.0],\n",
    "    [3.0,-1.0,0.5],\n",
    "    [0.5,1.0,1.0],\n",
    "    [1.0,1.0,-1.0]\n",
    "]\n",
    "ys= [1.0,-1.0,-1.0,1.0] #targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c21253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,7.687487914931491\n",
      "1,7.610488174633551\n",
      "2,7.371873185377382\n",
      "3,6.587464608845025\n",
      "4,4.0210897736138165\n",
      "5,3.066800055356951\n",
      "6,1.8190917611792388\n",
      "7,0.2254831016528278\n",
      "8,0.7823896699101042\n",
      "9,0.02086395827425442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Value(data=0.9403886843416586),\n",
       " Value(data=-0.9632518211349781),\n",
       " Value(data=-0.9781298084240874),\n",
       " Value(data=0.8755744584489453)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "for k in range(10):\n",
    "    # forward pass\n",
    "    ypred =[n(x) for x in xs]\n",
    "#     print(ypred)\n",
    "    loss = sum((yout-ygt)**2 for ygt,yout in zip(ys,ypred))\n",
    "    \n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "#     print(n.layers[0].neurons[0].w[0].grad)\n",
    "#     print(n.layers[0].neurons[0].w[0].data)\n",
    "\n",
    "    # update\n",
    "    for p in n.parameters():\n",
    "        p.data += -0.05 *p.grad\n",
    "        \n",
    "    print(f'{k},{loss.data}')\n",
    "\n",
    "ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4fc20e",
   "metadata": {},
   "source": [
    "#|hide\n",
    "\n",
    "The training loop above has a bug. Can you spot it?\n",
    "\n",
    "Essentially we forgot to zero out the gradients!! The gradients continued to accumulate and essentially gave us a huge step size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55781191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "n = MLP(3,[4,4,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5c3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,6.984012446543739\n",
      "1,5.2990932898900365\n",
      "2,2.7119446198737363\n",
      "3,1.1040438399237102\n",
      "4,0.6116998222981237\n",
      "5,0.39793797447474055\n",
      "6,0.28609778803102515\n",
      "7,0.21982528566041354\n",
      "8,0.17683287626830044\n",
      "9,0.14702658201211094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Value(data=0.8185364247619584),\n",
       " Value(data=-0.8521335877093006),\n",
       " Value(data=-0.7870031698836025),\n",
       " Value(data=0.7835157572695371)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|hide\n",
    "for k in range(10):\n",
    "    # forward pass\n",
    "    ypred =[n(x) for x in xs]\n",
    "    loss = sum((yout-ygt)**2 for ygt,yout in zip(ys,ypred))\n",
    "    \n",
    "    # backward pass\n",
    "    for p in n.parameters():\n",
    "        p.grad = 0 #zero grad\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    for p in n.parameters():\n",
    "        p.data += -0.05 * p.grad\n",
    "        p.grad = 0\n",
    "        \n",
    "    print(f'{k},{loss.data}')\n",
    "\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e72b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# view_dot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80bb2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
